{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CrateDB\n",
    "\n",
    "> [CrateDB] is capable of performing both vector and lexical search.\n",
    "> It is built on top of the Apache Lucene library, talks SQL,\n",
    "> is PostgreSQL-compatible, and scales like Elasticsearch.\n",
    "\n",
    "This notebook shows how to use the CrateDB vector store functionality around\n",
    "[`FLOAT_VECTOR`] and [`KNN_MATCH`]. You will learn how to use LangChain's\n",
    "`CrateDBVectorSearch` adapter for similarity search and other purposes.\n",
    "\n",
    "It supports:\n",
    "- Similarity Search with Euclidean Distance\n",
    "- Maximal Marginal Relevance Search (MMR)\n",
    "\n",
    "## What is CrateDB?\n",
    "\n",
    "[CrateDB] is an open-source, distributed, and scalable SQL analytics database\n",
    "for storing and analyzing massive amounts of data in near real-time, even with\n",
    "complex queries. It is PostgreSQL-compatible, based on [Lucene], and inherits\n",
    "the shared-nothing distribution layer of [Elasticsearch].\n",
    "\n",
    "This example uses the [Python client driver for CrateDB]. For more documentation,\n",
    "see also [LangChain with CrateDB].\n",
    "\n",
    "\n",
    "[CrateDB]: https://github.com/crate/crate\n",
    "[Elasticsearch]: https://github.com/elastic/elasticsearch\n",
    "[`FLOAT_VECTOR`]: https://cratedb.com/docs/crate/reference/en/latest/general/ddl/data-types.html#float-vector\n",
    "[`KNN_MATCH`]: https://cratedb.com/docs/crate/reference/en/latest/general/builtins/scalar-functions.html#scalar-knn-match\n",
    "[LangChain with CrateDB]: /docs/extras/integrations/providers/cratedb.html\n",
    "[Lucene]: https://github.com/apache/lucene\n",
    "[Python client driver for CrateDB]: https://cratedb.com/docs/python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "In order to use the CrateDB vector search you must install the sqlalchemy-cratedb package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install required packages: LangChain, OpenAI SDK, and the CrateDB SQLAlchemy adapter.\n",
    "%pip install -qU langchain-community langchain-openai sqlalchemy-cratedb"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### Credentials\n",
    "\n",
    "You will supply credentials through a regular SQLAlchemy connection string, like\n",
    "`crate://username:password@cratedb.example.org/`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "\n",
    "### OpenAI API key\n",
    "\n",
    "You need to provide an OpenAI API key, optionally using the environment\n",
    "variable `OPENAI_API_KEY`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-09T08:02:16.802456Z",
     "start_time": "2023-09-09T08:02:07.065604Z"
    }
   },
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "# Run `export OPENAI_API_KEY=sk-YOUR_OPENAI_API_KEY`.\n",
    "# Get OpenAI api key from `.env` file.\n",
    "# Otherwise, prompt for it.\n",
    "_ = load_dotenv(find_dotenv())\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\", getpass.getpass(\"OpenAI API key:\"))\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "You also need to provide a connection string to your CrateDB database cluster,\n",
    "optionally using the environment variable `CRATEDB_CONNECTION_STRING`.\n",
    "\n",
    "This example uses a CrateDB instance on your workstation, which you can start by\n",
    "running [CrateDB using Docker]. Alternatively, you can also connect to a cluster\n",
    "running on [CrateDB Cloud].\n",
    "\n",
    "[CrateDB Cloud]: https://console.cratedb.cloud/\n",
    "[CrateDB using Docker]: https://cratedb.com/docs/guide/install/container/\n",
    "\n",
    "### CrateDB connection string\n",
    "\n",
    "You will need to supply an SQLAlchemy-compatible connection string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "CONNECTION_STRING = os.environ.get(\n",
    "    \"CRATEDB_CONNECTION_STRING\",\n",
    "    \"crate://crate@localhost:4200/?schema=langchain\",\n",
    ")\n",
    "\n",
    "# For CrateDB Cloud, use:\n",
    "# CONNECTION_STRING = os.environ.get(\n",
    "#     \"CRATEDB_CONNECTION_STRING\",\n",
    "#     \"crate://username:password@hostname:4200/?ssl=true&schema=langchain\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-09T08:02:28.174088Z",
     "start_time": "2023-09-09T08:02:28.162698Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Alternatively, the connection string can be assembled from individual\n",
    "# environment variables.\n",
    "import os\n",
    "\n",
    "CONNECTION_STRING = CrateDBVectorSearch.connection_string_from_db_params(\n",
    "    driver=os.environ.get(\"CRATEDB_DRIVER\", \"crate\"),\n",
    "    host=os.environ.get(\"CRATEDB_HOST\", \"localhost\"),\n",
    "    port=int(os.environ.get(\"CRATEDB_PORT\", \"4200\")),\n",
    "    database=os.environ.get(\"CRATEDB_DATABASE\", \"langchain\"),\n",
    "    user=os.environ.get(\"CRATEDB_USER\", \"crate\"),\n",
    "    password=os.environ.get(\"CRATEDB_PASSWORD\", \"\"),\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Import Python Modules\n",
    "\n",
    "You will start by importing all required modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "from langchain.document_loaders import UnstructuredURLLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import CrateDBVectorSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manage vector store\n",
    "\n",
    "In the example above, you created a vector store from scratch. When\n",
    "aiming to work with an existing vector store, you can initialize it directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "store = CrateDBVectorSearch(\n",
    "    collection_name=\"testdrive\",\n",
    "    connection_string=CONNECTION_STRING,\n",
    "    embedding_function=embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add items to vector store\n",
    "\n",
    "You can also add documents to an existing vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store.add_documents([Document(page_content=\"foo\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "docs_with_score = store.similarity_search_with_score(\"foo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_with_score[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_with_score[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update items in vector store\n",
    "\n",
    "FIXME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Foo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete items from vector store\n",
    "FIXME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store.delete(ids=[\"foo\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Load and Index Documents\n",
    "\n",
    "Next, you will read input data, and tokenize it. The module will create a table\n",
    "with the name of the collection. Make sure the collection name is unique, and\n",
    "that you have the permission to create a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "loader = UnstructuredURLLoader(\n",
    "    \"https://github.com/langchain-ai/langchain/raw/v0.0.325/docs/docs/modules/state_of_the_union.txt\"\n",
    ")\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "COLLECTION_NAME = \"state_of_the_union_test\"\n",
    "\n",
    "db = CrateDBVectorSearch.from_documents(\n",
    "    embedding=embeddings,\n",
    "    documents=docs,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    connection_string=CONNECTION_STRING,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overwriting a Vector Store\n",
    "\n",
    "If you have an existing collection, you can overwrite it by using `from_documents`,\n",
    "aad setting `pre_delete_collection = True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = CrateDBVectorSearch.from_documents(\n",
    "    documents=docs,\n",
    "    embedding=embeddings,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    connection_string=CONNECTION_STRING,\n",
    "    pre_delete_collection=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_with_score = db.similarity_search_with_score(\"foo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_with_score[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Query vector store\n",
    "\n",
    "### Query directly\n",
    "\n",
    "#### Similarity search\n",
    "Searching by euclidean distance is the default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-09T08:05:11.104135Z",
     "start_time": "2023-09-09T08:05:10.548998Z"
    }
   },
   "outputs": [],
   "source": [
    "query = \"What did the president say about Ketanji Brown Jackson\"\n",
    "docs_with_score = db.similarity_search_with_score(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-09T08:05:13.532334Z",
     "start_time": "2023-09-09T08:05:13.523191Z"
    }
   },
   "outputs": [],
   "source": [
    "for doc, score in docs_with_score:\n",
    "    print(\"-\" * 80)\n",
    "    print(\"Score: \", score)\n",
    "    print(doc.page_content)\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Maximal Marginal Relevance Search (MMR)\n",
    "Maximal marginal relevance optimizes for similarity to query AND diversity among selected documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-09T08:05:23.276819Z",
     "start_time": "2023-09-09T08:05:21.972256Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "docs_with_score = db.max_marginal_relevance_search_with_score(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-09T08:05:27.478580Z",
     "start_time": "2023-09-09T08:05:27.470138Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for doc, score in docs_with_score:\n",
    "    print(\"-\" * 80)\n",
    "    print(\"Score: \", score)\n",
    "    print(doc.page_content)\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Searching in Multiple Collections\n",
    "`CrateDBVectorSearchMultiCollection` is a special adapter which provides similarity search across\n",
    "multiple collections. It can not be used for indexing documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores.cratedb import CrateDBVectorSearchMultiCollection\n",
    "\n",
    "multisearch = CrateDBVectorSearchMultiCollection(\n",
    "    collection_names=[\"test_collection_1\", \"test_collection_2\"],\n",
    "    embedding_function=embeddings,\n",
    "    connection_string=CONNECTION_STRING,\n",
    ")\n",
    "docs_with_score = multisearch.similarity_search_with_score(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Query by turning into retriever"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(retriever)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage for retrieval-augmented generation\n",
    "\n",
    "For guides on how to use this vector store for retrieval-augmented generation (RAG), see the following sections:\n",
    "\n",
    "- [Tutorials: working with external knowledge](https://python.langchain.com/docs/tutorials/#working-with-external-knowledge)\n",
    "- [How-to: Question and answer with RAG](https://python.langchain.com/docs/how_to/#qa-with-rag)\n",
    "- [Retrieval conceptual docs](https://python.langchain.com/docs/concepts/retrieval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API reference\n",
    "\n",
    "For detailed documentation of all `CrateDBVectorSearch` features and configurations,\n",
    "head to the API reference:\n",
    "https://python.langchain.com/api_reference/cratedb/vectorstores/langchain_cratedb.vectorstores.CrateDBVectorSearch.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
